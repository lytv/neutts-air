# NeuTTS Air ‚òÅÔ∏è

HuggingFace ü§ó: [Model](https://huggingface.co/neuphonic/neutts-air), [Q8 GGUF](https://huggingface.co/neuphonic/neutts-air-q8-gguf), [Q4 GGUF](https://huggingface.co/neuphonic/neutts-air-q4-gguf) [Spaces](https://huggingface.co/spaces/neuphonic/neutts-air)

[Demo Video](https://github.com/user-attachments/assets/020547bc-9e3e-440f-b016-ae61ca645184)

*Created by [Neuphonic](http://neuphonic.com/) - building faster, smaller, on-device voice AI*

State-of-the-art Voice AI has been locked behind web APIs for too long. NeuTTS Air is the world's first super-realistic, on-device, TTS speech language model with instant voice cloning. Built off a 0.5B LLM backbone, NeuTTS Air brings natural-sounding speech, real-time performance, built-in security and speaker cloning to your local device - unlocking a new category of embedded voice agents, assistants, toys, and compliance-safe apps.

## Key Features

- üó£ Best-in-class realism for its size - produces natural, ultra-realistic voices that sound human
- üì± Optimised for on-device deployment - provided in GGML format, ready to run on phones, laptops, or even Raspberry Pis
- üë´ Instant voice cloning - create your own speaker with as little as 3 seconds of audio
- üöÑ Simple LM + codec architecture built off a 0.5B backbone - the sweet spot between speed, size, and quality for real-world applications
- ‚ö° **NEW: Hotkey Service** - Copy text, press Control+Right Arrow, listen in ~2.3s!

## Model Details

NeuTTS Air is built off Qwen 0.5B - a lightweight yet capable language model optimised for text understanding and generation - as well as a powerful combination of technologies designed for efficiency and quality:
- **Supported Languages**: English
- **Audio Codec**: [NeuCodec](https://huggingface.co/neuphonic/neucodec) - our 50hz neural audio codec that achieves exceptional audio quality at low bitrates using a single codebook
- **Context Window**: 2048 tokens, enough for processing ~30 seconds of audio (including prompt duration)
- **Format**: Available in GGML format for efficient on-device inference
- **Responsibility**: Watermarked outputs
- **Inference Speed**: Real-time generation on mid-range devices (~2.3s on M1 CPU)
- **Power Consumption**: Optimised for mobile and embedded devices

---

## üöÄ Quick Setup (Automated)

Run the automated setup script:

```bash
./setup.sh
```

This will:
1. Install espeak (if needed)
2. Create virtual environment
3. Install all dependencies (including ONNX for speed)
4. Configure espeak for macOS
5. Pre-encode sample voices
6. Setup hotkey service
7. Create aliases for easy access

**Total time: ~2-3 minutes**

---

## üéπ Hotkey Service (Recommended)

The fastest way to use TTS - background service with global hotkeys!

### Quick Start

   ```bash
tts-start      # Start service (wait ~10s for model loading)
```

**Then:**
1. Copy any text (Cmd+C)
2. Press **Control+Right Arrow** to generate and play
3. Press **Control+Left Arrow** to replay last audio
4. Listen! (~2.3 seconds)

**Stop:**
- Press **Cmd+Shift+Q** (or run `tts-stop`)

### Performance

- **First start:** ~7-10s (load models once)
- **Each use:** ~2.3s (clipboard ‚Üí audio playing)
- **Memory:** ~2GB RAM while running
- **Stop:** <1s (frees RAM)

### Aliases

   ```bash
tts-start      # Start background service
tts-stop       # Stop service and free RAM
tts-status     # Check service status
tts-fast       # Interactive mode (manual)
```

### Architecture

```
Copy text (Cmd+C) ‚Üí Press Control+Right Arrow ‚Üí 2.3s ‚Üí Audio plays!
                         ‚Üì
              Background Service (models loaded)
                         ‚Üì
Press Control+Left Arrow ‚Üí Replay last audio instantly!
```

---

## üì¶ Manual Setup (If you prefer step-by-step)

### 1. Install espeak

   ```bash
# macOS
   brew install espeak

   # Ubuntu/Debian
   sudo apt install espeak
   ```

### 2. Setup Python Environment

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install optional (but recommended) packages for speed
pip install llama-cpp-python onnxruntime pynput pyperclip
```

### 3. Configure espeak for macOS

The setup script handles this automatically. If needed manually, espeak library path is already configured in `neuttsair/neutts.py`.

---

## üí° Usage Examples

### Option 1: Hotkey Service (Fastest) ‚≠ê

```bash
tts-start
# Copy text anywhere ‚Üí Press Control+Right Arrow ‚Üí Listen!
```

### Option 2: Interactive Mode

```bash
python blazing_fast_tts.py --onnx
# Type text at prompt, get audio in ~2.3s
```

### Option 3: Command Line

```bash
python blazing_fast_tts.py --onnx --text "Hello world"
```

### Option 4: Python Script

```python
from neuttsair.neutts import NeuTTSAir
import soundfile as sf

tts = NeuTTSAir(
    backbone_repo="neuphonic/neutts-air-q4-gguf",  # Quantized for speed
   backbone_device="cpu",
    codec_repo="neuphonic/neucodec-onnx-decoder",  # ONNX for speed
   codec_device="cpu"
)

# Load pre-encoded reference
import torch
ref_codes = torch.load("samples/dave.pt")
ref_text = open("samples/dave.txt").read().strip()

# Generate
wav = tts.infer("Hello, this is a test.", ref_codes, ref_text)
sf.write("output.wav", wav, 24000)
```

---

## ‚ö° Performance Optimization

This setup is optimized for maximum speed on Apple Silicon:

### Applied Optimizations

1. **GGUF Q4 Quantization** - 70% smaller model, 30% faster
2. **ONNX Decoder** - 10-20% faster audio decoding
3. **Pre-encoded References** - No re-encoding overhead
4. **Background Service** - Models stay loaded in RAM
5. **Metal GPU** - Automatic Apple Silicon acceleration

### Benchmark Results (M1 CPU)

| Method | Time |
|--------|------|
| **Hotkey Service** | **2.3s** ‚ö° |
| Interactive Mode | 2.3s |
| Script (with reload) | 9.3s |
| Original Basic | 60-90s |

**Result: 75% faster than default, on-par with cloud services!**

---

## üé§ Voice References

Two pre-configured voices are included:

- **dave** - Male voice (`samples/dave.wav`)
- **jo** - Female voice (`samples/jo.wav`)

### Using Different Voices

Edit the service configuration or specify in command:

```bash
python blazing_fast_tts.py --onnx --voice jo --text "Hello"
```

### Adding Custom Voices

1. Record 3-15 seconds of clean audio (mono, 16-44kHz, .wav)
2. Save as `samples/yourname.wav`
3. Create `samples/yourname.txt` with the transcript
4. Pre-encode: `python -c "from blazing_fast_tts import BlazingFastTTS; ..."` (see examples)

---

## üîß Service Management

### Start Service

```bash
tts-start
# Or: ./tts-start.sh
```

### Stop Service

```bash
tts-stop
# Or: ./tts-stop.sh
# Or: Press Cmd+Shift+Q
```

### Check Status

```bash
tts-status
# Shows: running status, PIDs, memory usage
```

### View Logs

```bash
tail -f /tmp/tts_service.log     # Service logs
tail -f /tmp/tts_hotkey.log      # Hotkey logs
```

---

## üêõ Troubleshooting

### Hotkey Not Working

**Issue:** Control+Right Arrow does nothing

**Solution:**
1. Check macOS permissions: System Settings ‚Üí Privacy & Security ‚Üí Accessibility
2. Enable Terminal/Python
3. Restart service: `tts-stop && tts-start`

### Service Won't Start

**Issue:** `tts-start` fails

**Solution:**
```bash
# Stop any existing processes
tts-stop

# Check logs
tail -20 /tmp/tts_service.log

# Restart
tts-start
```

### Slow Performance

**Issue:** Takes longer than 2.3s

**Solution:**
1. Verify ONNX is installed:
   ```bash
   source venv/bin/activate
   python -c "import onnxruntime; print('OK')"
   ```

2. If not, install it:
   ```bash
   pip install onnxruntime
   ```

3. Restart service:
   ```bash
   tts-stop && tts-start
   ```

### espeak Not Found (macOS)

**Issue:** espeak library error

**Solution:**
```bash
# Install espeak
brew install espeak

# Library path is already configured in neuttsair/neutts.py
# But if needed, check: /opt/homebrew/Cellar/espeak/*/lib/
```

### Memory Issues

**Issue:** System running out of RAM

**Solution:**
- Stop service when not in use: `tts-stop` or Cmd+Shift+Q
- Service uses ~2GB RAM while running
- RAM is freed immediately when stopped

---

## üìä System Requirements

- **OS:** macOS 10.13+ (optimized for Apple Silicon)
- **Python:** 3.11 or higher
- **RAM:** 4GB minimum (8GB recommended)
- **Storage:** ~2GB for models
- **Dependencies:** espeak, PyTorch, llama-cpp-python, onnxruntime

---

## üéØ Quick Reference

### Hotkey Service

| Action | Command/Hotkey |
|--------|----------------|
| Setup | `./setup.sh` |
| Start | `tts-start` or `./tts-start.sh` |
| Use | Copy text, press **Control+Right Arrow** |
| Replay | Press **Control+Left Arrow** to replay last audio |
| Stop | **Cmd+Shift+Q** or `tts-stop` |
| Status | `tts-status` |

### Performance

| Metric | Time |
|--------|------|
| Setup (one time) | 2-3 minutes |
| First start | 7-10 seconds |
| Clipboard ‚Üí Audio | **2.3 seconds** ‚ö° |
| Stop service | <1 second |

### Files

| File | Purpose |
|------|---------|
| `setup.sh` | Automated setup |
| `tts-start.sh` | Start service |
| `tts-stop.sh` | Stop service |
| `tts-status.sh` | Check status |
| `tts_service.py` | Background daemon |
| `tts_hotkey.py` | Hotkey listener |
| `blazing_fast_tts.py` | Interactive/CLI mode |

---

## üî¨ Technical Details

### Architecture

**Background Service Mode:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   macOS Global Hotkey Listener     ‚îÇ
‚îÇ        (tts_hotkey.py)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ Unix Socket
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      TTS Background Service         ‚îÇ
‚îÇ       (tts_service.py)              ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Models (Pre-loaded in RAM)   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - GGUF Q4 Backbone (~400MB)  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - ONNX Decoder (~100MB)      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Pre-encoded Voices         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  Generate (~2.0s) + Play (~0.3s)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Interactive Mode:**
```
User Input ‚Üí TTS Engine (loaded) ‚Üí Audio Generation ‚Üí Play
```

### Speed Breakdown (2.3s total)

1. Model inference: ~2.0s (84%)
2. Audio decoding: ~0.2s (9%)
3. Watermarking: ~0.1s (4%)
4. Overhead: ~0.0s (3%)

**Note:** 2.0s model inference is the hardware limit on M1 CPU with this model size.

---

## üéì Advanced Features

### Change Default Voice

Edit `tts_service.py`:
```python
self.current_voice = 'jo'  # Change from 'dave'
```

Restart: `tts-stop && tts-start`

### Custom Hotkeys

Edit `tts_hotkey.py`:
```python
hotkeys = {
    '<cmd>+<alt>+t': self.on_speak_hotkey,  # Change from default speak hotkey
    '<cmd>+<alt>+q': self.on_quit_hotkey,   # Change from Cmd+Shift+Q
}
```

### Programmatic Access

Send requests via Unix socket:
```bash
echo '{"action": "speak", "text": "Hello world"}' | nc -U /tmp/tts_service.sock
```

Response:
```json
{"status": "success", "time": 2.3, "message": "Generated in 2.3s"}
```

### Batch Processing

Process multiple texts efficiently:
```python
# Service stays loaded, just send multiple requests
for text in texts:
    response = send_request('speak', text=text)
    # Each takes ~2.3s, not 9.3s!
```

---

## üìö Examples

### Example 1: Reading Articles

```bash
# Start service
tts-start

# While reading article in browser:
# 1. Select paragraph
# 2. Copy (Cmd+C)
# 3. Press Control+Right Arrow
# 4. Listen while scrolling!
```

### Example 2: Email Reading

```bash
# Open email
# Copy message ‚Üí Control+Right Arrow
# Listen while doing other tasks
```

### Example 3: Code Review

```bash
# Copy code comments
# Control+Right Arrow
# Listen while reviewing code
```

### Example 4: Accessibility

Use TTS for:
- Reading documents aloud
- Verifying typed text
- Resting eyes while listening
- Multitasking

---

## üîÑ Update & Maintenance

### Update Models

Models are cached in `~/.cache/huggingface/`. To update:

```bash
rm -rf ~/.cache/huggingface/hub/models--neuphonic*
tts-start  # Will re-download latest
```

### Update Code

```bash
git pull origin main
./setup.sh  # Re-run setup if needed
```

### Clean Logs

```bash
rm /tmp/tts_*.log
```

### Uninstall

```bash
tts-stop
rm -rf venv
rm -rf ~/.cache/huggingface/hub/models--neuphonic*
# Remove aliases from ~/.zshrc if desired
```

---

## ü§ù Contributing

This repo includes optimizations for Apple Silicon. Original project:

- Original repo: [neuphonic/neutts-air](https://github.com/neuphonic/neutts-air)
- Pre-commit hooks: Run `pre-commit install` for contributors

---

## üìÑ License

See LICENSE file.

---

## üéâ Summary

This setup provides:

‚úÖ **Instant TTS** - Background service with hotkeys  
‚úÖ **2.3s performance** - Optimized for M1/M2/M3  
‚úÖ **Easy setup** - One command: `./setup.sh`  
‚úÖ **System-wide** - Works in any app  
‚úÖ **Offline & Free** - No API costs, no internet needed  
‚úÖ **Private** - All processing on-device  

### Get Started Now

```bash
./setup.sh          # Setup (2-3 minutes)
tts-start           # Start service (10 seconds)
# Copy text ‚Üí Control+Right Arrow ‚Üí Listen!
```

**Enjoy your instant TTS! ‚ö°**

---

## üÜò Support

- Check status: `tts-status`
- View logs: `tail -f /tmp/tts_service.log`
- Restart: `tts-stop && tts-start`
- Issues: See Troubleshooting section above

For original NeuTTS Air issues: https://github.com/neuphonic/neutts-air/issues
